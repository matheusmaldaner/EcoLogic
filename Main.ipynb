{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df65bb0b-594d-4717-bd3c-63b04b9d864b",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb5dd1c0-73cf-4679-ae21-6fa00a85a395",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import yaml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Compose, Lambda\n",
    "import mnist_dataset\n",
    "from hydra import initialize, compose\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset\n",
    "from difflogic import LogicLayer, GroupSum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99c41f-b5c7-4d64-a704-5a003a5b56c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8096d-fc17-46d7-861e-685d2fe12dbb",
   "metadata": {},
   "source": [
    "Tunable Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47ea8409-a084-4bee-8121-96acd99bb28e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# True: Removes border of Mnist, False: Keeps black border around digits\n",
    "remove_border = False\n",
    "# True: Binarized Images, False: Grayscale Images \n",
    "binarize_images = True  \n",
    "# True: Even distribution of samples, False: Original Mnist distribution \n",
    "evenly_partitioned = True\n",
    "# True: Upscales the samples to 32x32, False: Keeps size unchanged\n",
    "upscaled_images = True\n",
    "# Batch size\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4450630-e7a8-4564-b106-6e2dc3a12e61",
   "metadata": {},
   "source": [
    "Dataset Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1779afcd-2def-41d1-abdc-c1bc8dbb1719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to binarize an image, threshold is tunable \n",
    "def binarize(image, threshold=0.5):\n",
    "    return (image > threshold).float()  \n",
    "\n",
    "# define the transformation logic based on the toggle\n",
    "transform_list = [ToTensor()]\n",
    "if upscaled_images:\n",
    "    transform_list.append(Resize((32, 32)))\n",
    "if binarize_images:\n",
    "    transform_list.append(Lambda(lambda x: binarize(x)))\n",
    "    \n",
    "transform = Compose(transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d9255d2-bf0c-4bab-b66a-b65360bcb86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = mnist_dataset.MNIST('./data-mnist', train=True, download=True, remove_border=remove_border, transform=transform)\n",
    "test_dataset = mnist_dataset.MNIST('./data-mnist', train=False, remove_border=remove_border, transform=transform)\n",
    "\n",
    "# drop_last = True means it will drop the last incomplete Batch\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38a5db70-d2ba-44a7-803c-829177a182c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes the Dataset evenly partitioned\n",
    "if evenly_partitioned:\n",
    "    # code below is used so that all classes have the same number of samples\n",
    "    train_targets = train_loader.dataset.targets\n",
    "    test_targets = test_loader.dataset.targets\n",
    "\n",
    "    train_digits_total = []\n",
    "    test_digits_total = []\n",
    "\n",
    "    for i in range(10):\n",
    "        curr_tot_train = torch.sum(train_targets == i).item()\n",
    "        curr_tot_test = torch.sum(test_targets == i).item()    \n",
    "        train_digits_total.append(curr_tot_train)\n",
    "        test_digits_total.append(curr_tot_test)\n",
    "\n",
    "    train_digits_total, test_digits_total\n",
    "\n",
    "    # find the minimum number of samples across all classes\n",
    "    min_samples_train = min(train_digits_total)\n",
    "    min_samples_test = min(test_digits_total)\n",
    "\n",
    "    # function to trim dataset to match the minimum samples for each class and shuffle indices\n",
    "    def trim_dataset(dataset, targets, min_samples):\n",
    "        indices = []\n",
    "        for i in range(10):\n",
    "            class_indices = (targets == i).nonzero(as_tuple=True)[0]  # get indices of class i\n",
    "            class_indices = class_indices[:min_samples]  # trim to min_samples\n",
    "            indices.extend(class_indices)\n",
    "\n",
    "        # shuffle indices after collecting them\n",
    "        indices = torch.tensor(indices)\n",
    "        indices = indices[torch.randperm(indices.size(0))]  \n",
    "\n",
    "        return Subset(dataset, indices)\n",
    "\n",
    "    # trim both train and test datasets to ensure all classes have the same number of samples\n",
    "    trimmed_train_dataset = trim_dataset(train_loader.dataset, train_targets, min_samples_train)\n",
    "    trimmed_test_dataset = trim_dataset(test_loader.dataset, test_targets, min_samples_test)\n",
    "\n",
    "    # create DataLoaders for the trimmed datasets\n",
    "    trimmed_train_loader = DataLoader(trimmed_train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    trimmed_test_loader = DataLoader(trimmed_test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, drop_last=True)\n",
    "\n",
    "    # verify the lengths of the trimmed datasets\n",
    "    len(trimmed_train_loader.dataset), len(trimmed_test_loader.dataset)\n",
    "\n",
    "    train_dataset = trimmed_train_dataset\n",
    "    test_dataset = trimmed_test_dataset\n",
    "    train_loader = trimmed_train_loader\n",
    "    test_loader = trimmed_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aebb9b7f-2399-4b9f-8a8a-570c922f92ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54210, 8920)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = len(train_loader.dataset) + len(test_loader.dataset)\n",
    "len(train_loader.dataset), len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66230413-408e-4bc1-bf5f-2313690e0964",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14d236da2a60>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_size = len(train_dataset)\n",
    "random_index = random.randint(0, dataset_size - 1)\n",
    "\n",
    "if remove_border:\n",
    "    image = train_loader.dataset[random_index][0].reshape(20, 20)\n",
    "elif not remove_border and not upscaled_images:\n",
    "    image = train_loader.dataset[random_index][0].reshape(28, 28)\n",
    "else:\n",
    "    image = train_loader.dataset[random_index][0].reshape(32, 32)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973f0e3-5f32-4793-afc6-9394425419de",
   "metadata": {},
   "source": [
    "#### Model Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4e63be-c489-4aaf-a605-9e1d0fda631f",
   "metadata": {},
   "source": [
    "Converts csv into yaml config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9b89fd2-f200-40c1-973a-489ef4190e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define first input and the name of the file to be saved\n",
    "first_in_dim = 1024 # 32x32\n",
    "filename = \"config/mnist_config_32x32.yaml\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4dc64546-f1d7-4e18-b88c-7140d4d42692",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file 'config/mnist_config_32x32.yaml' generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# reads the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"config/hyperparameters.csv\")\n",
    "\n",
    "# convert the DataFrame to a list of dictionaries\n",
    "models = df.to_dict(orient=\"records\")\n",
    "\n",
    "# create the YAML structure\n",
    "yaml_structure = {\"models\": {}}\n",
    "\n",
    "# rounds the number to the nearest multiple of the output size\n",
    "def round_to_nearest_multiple(value, multiple):\n",
    "    return multiple * round(value / multiple)\n",
    "\n",
    "# populate the YAML structure with models\n",
    "for i, model in enumerate(models, start=1):\n",
    "    # zero-padding model names to 3 digits \n",
    "    model_name = f\"model_{str(i).zfill(3)}\"\n",
    "    layers_config = {}\n",
    "    \n",
    "    for layer in range(1, model[\"H\"] + 1):\n",
    "        # zero-padding the layer names to 3 digits\n",
    "        layer_name = f\"LogicLayer{str(layer).zfill(3)}\"\n",
    "        \n",
    "        # adjusts in_dim to the nearest multiple of 10\n",
    "        in_dim = first_in_dim if layer == 1 else round_to_nearest_multiple(model[\"W\"], 10)\n",
    "        \n",
    "        # adjusts out_dim to the nearest multiple of 10\n",
    "        out_dim = round_to_nearest_multiple(model[\"W\"], 10)\n",
    "        \n",
    "        layers_config[layer_name] = {\n",
    "            \"in_dim\": in_dim,\n",
    "            \"out_dim\": out_dim,\n",
    "            \"device\": \"cuda\",\n",
    "            \"implementation\": \"cuda\",\n",
    "            \"connections\": \"random\",\n",
    "            \"grad_factor\": 2, # we can try different grad_factor values as well\n",
    "        }\n",
    "    \n",
    "    yaml_structure[\"models\"][model_name] = {\n",
    "        \"input_dim\": first_in_dim, \n",
    "        \"output_size\": 10, # for MNIST classification\n",
    "        \"tau\": model[\"tau\"],\n",
    "        \"learning_rate\": model[\"lr\"],\n",
    "        \"layers_config\": layers_config,\n",
    "    }\n",
    "\n",
    "# saves to a YAML file\n",
    "with open(f'{filename}', \"w\") as file:\n",
    "    yaml.dump(yaml_structure, file, default_flow_style=False)\n",
    "\n",
    "print(f\"YAML file '{filename}' generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e939ace-e4c3-4781-bdea-f9722ddb925e",
   "metadata": {},
   "source": [
    "#### Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473370c-ec74-455b-854c-f597d04144f3",
   "metadata": {},
   "source": [
    "DiffLogic Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b244edec-9bd5-474d-9aaa-4f9aafe31b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffLogic(nn.Module):\n",
    "    def __init__(self, layers_config, output_size, tau=30):\n",
    "        \"\"\"\n",
    "        Initializes the DiffLogic model with the specified layer configurations, output size, and temperature parameter.\n",
    "\n",
    "        Args:\n",
    "            layers_config (dict): Configuration for each logic layer, including dimensions, device, implementation, connections, and grad factor.\n",
    "            output_size (int): The number of output groups (classes in a classification problem).\n",
    "            tau (int): Temperature parameter for the GroupSum operation.\n",
    "        \"\"\"\n",
    "        super(DiffLogic, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # stores the logic layers\n",
    "        layers = []\n",
    "        for layer_name, config in layers_config.items():\n",
    "            layer = LogicLayer(\n",
    "                in_dim=config['in_dim'],\n",
    "                out_dim=config['out_dim'],\n",
    "                device=config['device'],\n",
    "                implementation=config['implementation'],\n",
    "                connections=config['connections'],\n",
    "                grad_factor=config['grad_factor']       \n",
    "            )\n",
    "            layers.append(layer)\n",
    "            print(layer)\n",
    "        \n",
    "        self.logic_layers = nn.Sequential(*layers)\n",
    "        self.group = GroupSum(k=output_size, tau=tau)\n",
    "        self.log_text = \"\"  # initializes logging string\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the DiffLogic model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after processing through the logic layers and grouping operation.\n",
    "        \"\"\"\n",
    "        # moves tensor to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.to('cuda')          \n",
    "        x = self.flatten(x)\n",
    "        logits = self.logic_layers(x)\n",
    "        group = self.group(logits)\n",
    "        return group\n",
    "    \n",
    "    def save(self, file_path, model_name='model'):\n",
    "        \"\"\"\n",
    "        Saves the model's state dictionary to the specified file path.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path where the model will be saved.\n",
    "            model_name (str): Name of the saved model\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        torch.save({\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'connections': [layer.indices for layer in self.logic_layers if isinstance(layer, LogicLayer)]\n",
    "        }, os.path.join(file_path, f\"{model_name}.pth\"))\n",
    "        self.log_text += f\"Model saved to: {file_path}\\n\"\n",
    "\n",
    "    def load(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads the model's state dictionary from the specified file path.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path from which the model will be loaded.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(file_path)\n",
    "        self.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        # assigns connections to each LogicLayer\n",
    "        for idx, layer in enumerate(self.logic_layers):\n",
    "            if isinstance(layer, LogicLayer):\n",
    "                layer.indices = checkpoint['connections'][idx]\n",
    "\n",
    "        self.eval()\n",
    "        self.log_text += f\"Model loaded from: {file_path}\\n\"\n",
    "        \n",
    "    def get_accuracy(self, data_loader):\n",
    "        \"\"\"\n",
    "        Calculates the accuracy of the model against a data loader\n",
    "\n",
    "        Args:\n",
    "            data_loader: a DataLoader object, e.g. train_loader or test_loader\n",
    "\n",
    "        Returns:\n",
    "            float: The accuracy\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # ensures that model is in evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation for inference\n",
    "            for batch_inputs, batch_outputs in tqdm(data_loader, desc=\"Running Inference\"):\n",
    "                batch_inputs, batch_outputs = batch_inputs.to('cuda'), batch_outputs.to('cuda')\n",
    "\n",
    "                # forward pass to get predictions\n",
    "                outputs = self(batch_inputs)\n",
    "\n",
    "                # gets the predicted class (index of the maximum logit)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # counting correct predictions\n",
    "                total += batch_outputs.size(0)  # total number of samples in the batch\n",
    "                correct += (predicted == batch_outputs).sum().item()  # counting correct predictions\n",
    "\n",
    "        accuracy = correct / total\n",
    "        return accuracy\n",
    "\n",
    "    def get_log(self):\n",
    "        \"\"\"\n",
    "        Retrieves the log text and clears the log after retrieval.\n",
    "\n",
    "        Returns:\n",
    "            str: The log text.\n",
    "        \"\"\"\n",
    "        log_copy = self.log_text\n",
    "        self.log_text = \"\"  # Clear the log after returning\n",
    "        return log_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5632fa27-5e05-41b0-b3a3-ac941714657b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=10, min_delta=0):\n",
    "        \"\"\"\n",
    "        Initializes the EarlyStopper to stop training if the performance doesn't improve after a certain number of epochs.\n",
    "\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait for an improvement.\n",
    "            min_delta (float): Minimum change to consider an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "\n",
    "    def should_stop(self, current_loss):\n",
    "        \"\"\"\n",
    "        Check if training should stop based on the current loss.\n",
    "\n",
    "        Args:\n",
    "            current_loss (float): The current loss.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if training should stop, False otherwise.\n",
    "        \"\"\"\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = current_loss\n",
    "            return False\n",
    "        elif current_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = current_loss\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(\"EarlyStopper Triggered: \", self.counter)\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd97e0b-c6c4-4262-97ab-32136126ba39",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dea90015-6e45-49af-bb11-539c8811adcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model model_001\n",
      "ERROR TRAINING MODEL_001: The number of neurons (510) must not be smaller than half of the number of inputs (1024) because otherwise not all inputs could be used or considered.\n",
      "training model model_002\n",
      "LogicLayer(1024, 1020, train)\n",
      "LogicLayer(1020, 1020, train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 211/211 [00:06<00:00, 34.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.8319219416777452\n",
      "ERROR TRAINING MODEL_002: [Errno 2] No such file or directory: 'trained_models/mnist_trained_32x32/model_002.pth'\n",
      "training model model_003\n",
      "LogicLayer(1024, 2050, train)\n",
      "LogicLayer(2050, 2050, train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 211/211 [00:06<00:00, 33.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.4657695267594173\n",
      "ERROR TRAINING MODEL_003: [Errno 2] No such file or directory: 'trained_models/mnist_trained_32x32/model_003.pth'\n",
      "training model model_004\n",
      "LogicLayer(1024, 4100, train)\n",
      "LogicLayer(4100, 4100, train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 211/211 [00:06<00:00, 33.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.007454090534806\n",
      "ERROR TRAINING MODEL_004: [Errno 2] No such file or directory: 'trained_models/mnist_trained_32x32/model_004.pth'\n",
      "training model model_005\n",
      "LogicLayer(1024, 7420, train)\n",
      "LogicLayer(7420, 7420, train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 211/211 [00:06<00:00, 33.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.7004645685741194\n",
      "ERROR TRAINING MODEL_005: [Errno 2] No such file or directory: 'trained_models/mnist_trained_32x32/model_005.pth'\n",
      "training model model_006\n",
      "ERROR TRAINING MODEL_006: The number of neurons (510) must not be smaller than half of the number of inputs (1024) because otherwise not all inputs could be used or considered.\n",
      "training model model_007\n",
      "LogicLayer(1024, 1020, train)\n",
      "LogicLayer(1020, 1020, train)\n",
      "LogicLayer(1020, 1020, train)\n",
      "LogicLayer(1020, 1020, train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  55%|█████▌    | 117/211 [00:03<00:02, 32.68it/s]\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x14d23c74bac0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/blue/woodard/mkunzlermaldaner/project/SKEPTIC/schoolhouse_ex/X_StateEmbedding/env/difflogic_env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(train_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# to track loss for an epoch\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_inputs, batch_outputs \u001b[38;5;129;01min\u001b[39;00m loop:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# move data to the appropriate device\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     39\u001b[0m     batch_inputs, batch_outputs \u001b[38;5;241m=\u001b[39m batch_inputs\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mdouble(), batch_outputs\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong()\n",
      "File \u001b[0;32m/blue/woodard/mkunzlermaldaner/project/SKEPTIC/schoolhouse_ex/X_StateEmbedding/env/difflogic_env/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/blue/woodard/mkunzlermaldaner/project/SKEPTIC/schoolhouse_ex/X_StateEmbedding/env/difflogic_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/blue/woodard/mkunzlermaldaner/project/SKEPTIC/schoolhouse_ex/X_StateEmbedding/env/difflogic_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/blue/woodard/mkunzlermaldaner/project/SKEPTIC/schoolhouse_ex/X_StateEmbedding/env/difflogic_env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/blue/woodard/mkunzlermaldaner/project/SKEPTIC/schoolhouse_ex/X_StateEmbedding/env/difflogic_env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/blue/woodard/mkunzlermaldaner/project/SKEPTIC/schoolhouse_ex/X_StateEmbedding/env/difflogic_env/lib/python3.9/site-packages/torch/utils/data/dataset.py:311\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/blue/woodard/mkunzlermaldaner/project/EcoLogic/mnist_dataset.py:194\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    191\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m/blue/woodard/mkunzlermaldaner/project/SKEPTIC/schoolhouse_ex/X_StateEmbedding/env/difflogic_env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:60\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 60\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/blue/woodard/mkunzlermaldaner/project/SKEPTIC/schoolhouse_ex/X_StateEmbedding/env/difflogic_env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:97\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m     90\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/woodard/mkunzlermaldaner/project/SKEPTIC/schoolhouse_ex/X_StateEmbedding/env/difflogic_env/lib/python3.9/site-packages/torchvision/transforms/functional.py:129\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    127\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[1;32m    128\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\n\u001b[0;32m--> 129\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    133\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize Hydra with the config path and job name\n",
    "with initialize(version_base=None, config_path=\"config\", job_name=\"aidays2024\"):\n",
    "    cfg = compose(config_name=\"mnist_config_32x32\")\n",
    "\n",
    "# training loop for all models\n",
    "all_models_dict = {}\n",
    "num_epochs = 1\n",
    "file_path = 'trained_models/mnist_trained_32x32' # where to save your trained models\n",
    "\n",
    "# loops through all model configs and trains each of them\n",
    "for model_name, model_cfg in cfg.models.items():\n",
    "    print(f'training model {model_name}')\n",
    "\n",
    "    # tracking dictionary\n",
    "    all_models_dict[model_name] = {\n",
    "        'losses': [],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # initializes DiffLogic model and moves to CUDA if available\n",
    "        model = DiffLogic(layers_config=model_cfg['layers_config'], \n",
    "                          output_size=model_cfg['output_size'], \n",
    "                          tau=model_cfg['tau']).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # optimizer and loss criterion\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=model_cfg['learning_rate'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # early stopping\n",
    "        early_stopper = EarlyStopper(patience=5)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            loop = tqdm(train_loader, leave=True, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "            epoch_loss = 0  # to track loss for an epoch\n",
    "            \n",
    "            for batch_inputs, batch_outputs in loop:\n",
    "                # move data to the appropriate device\n",
    "                device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "                batch_inputs, batch_outputs = batch_inputs.to(device).double(), batch_outputs.to(device).long()\n",
    "\n",
    "                # forward pass through the model\n",
    "                predictions = model(batch_inputs)\n",
    "                loss = criterion(predictions, batch_outputs)\n",
    "\n",
    "                # zero gradients, backpropagates, and updates model parameters\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # accumulating the loss for the epoch\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            # caclulating the average loss for the epoch\n",
    "            epoch_loss /= len(train_loader)\n",
    "            all_models_dict[model_name]['losses'].append(epoch_loss)\n",
    "            print(f'Epoch {epoch+1} Loss: {epoch_loss}')\n",
    "\n",
    "            # checks for early stopping\n",
    "            if early_stopper.should_stop(epoch_loss):\n",
    "                print(f\"Early stopping triggered for {model_name} at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "        # saving trained model's state\n",
    "        model.save(file_path, model_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR TRAINING {model_name.upper()}: {str(e)}\")\n",
    "\n",
    "print(\"All models processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28a834-adac-4241-83a4-d9a23ac17db5",
   "metadata": {},
   "source": [
    "#### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33048f62-fc21-4f87-b725-6eb470a66700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogicLayer(1024, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "Evaluating model_001.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_001.pth: 81.64%\n",
      "\n",
      "LogicLayer(1024, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "Evaluating model_002.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_002.pth: 86.73%\n",
      "\n",
      "LogicLayer(1024, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "Evaluating model_003.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_003.pth: 89.38%\n",
      "\n",
      "LogicLayer(1024, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "Evaluating model_004.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_004.pth: 90.60%\n",
      "\n",
      "LogicLayer(1024, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "Evaluating model_005.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:01<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_005.pth: 90.06%\n",
      "\n",
      "LogicLayer(1024, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "Evaluating model_006.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_006.pth: 86.11%\n",
      "\n",
      "LogicLayer(1024, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "Evaluating model_007.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_007.pth: 90.59%\n",
      "\n",
      "LogicLayer(1024, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "Evaluating model_008.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_008.pth: 92.46%\n",
      "\n",
      "LogicLayer(1024, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "Evaluating model_009.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_009.pth: 93.10%\n",
      "\n",
      "LogicLayer(1024, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "Evaluating model_010.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_010.pth: 93.76%\n",
      "\n",
      "LogicLayer(1024, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "Evaluating model_011.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_011.pth: 86.50%\n",
      "\n",
      "LogicLayer(1024, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "Evaluating model_012.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_012.pth: 91.25%\n",
      "\n",
      "LogicLayer(1024, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "Evaluating model_013.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_013.pth: 92.82%\n",
      "\n",
      "LogicLayer(1024, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "Evaluating model_014.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_014.pth: 93.89%\n",
      "\n",
      "LogicLayer(1024, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "Evaluating model_015.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 34.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_015.pth: 94.29%\n",
      "\n",
      "LogicLayer(1024, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "Evaluating model_016.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 35.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_016.pth: 85.66%\n",
      "\n",
      "LogicLayer(1024, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "Evaluating model_017.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 34.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_017.pth: 91.04%\n",
      "\n",
      "LogicLayer(1024, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "Evaluating model_018.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 34.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_018.pth: 92.35%\n",
      "\n",
      "LogicLayer(1024, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "Evaluating model_019.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 34.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_019.pth: 93.23%\n",
      "\n",
      "LogicLayer(1024, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "Evaluating model_020.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 34.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_020.pth: 93.36%\n",
      "\n",
      "LogicLayer(1024, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "LogicLayer(2560, 2560, train)\n",
      "Evaluating model_021.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 34.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_021.pth: 79.58%\n",
      "\n",
      "LogicLayer(1024, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "LogicLayer(5120, 5120, train)\n",
      "Evaluating model_022.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 34.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_022.pth: 86.87%\n",
      "\n",
      "LogicLayer(1024, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "LogicLayer(7680, 7680, train)\n",
      "Evaluating model_023.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 34.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_023.pth: 89.48%\n",
      "\n",
      "LogicLayer(1024, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "LogicLayer(10240, 10240, train)\n",
      "Evaluating model_024.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 34.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_024.pth: 90.20%\n",
      "\n",
      "LogicLayer(1024, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "LogicLayer(12800, 12800, train)\n",
      "Evaluating model_025.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:00<00:00, 34.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_025.pth: 91.89%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# testing loop to test inferences\n",
    "trained_models_dir = 'trained_models/mnist_trained_32x32'\n",
    "\n",
    "# retrieves a list of all model files in the directory\n",
    "model_files = sorted([f for f in os.listdir(trained_models_dir) if f.endswith('.pth')])\n",
    "\n",
    "with initialize(version_base=None, config_path=\"config\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"mnist_config_32x32\")\n",
    "\n",
    "# dictionary to store the trained models\n",
    "trained_models = {}\n",
    "\n",
    "# loops through all model files and calculates their accuracies\n",
    "for i, model_file in enumerate(model_files):\n",
    "    if model_file.endswith('_weights.pth'):\n",
    "        model_name = model_file.removesuffix('_weights.pth')\n",
    "    else:\n",
    "        model_name = model_file.removesuffix('.pth')\n",
    "    \n",
    "    model_cfg = cfg['models'][model_name]\n",
    "    \n",
    "    # instantiates the model and load its weights\n",
    "    model = DiffLogic(layers_config=model_cfg['layers_config'], \n",
    "                          output_size=model_cfg['output_size'], \n",
    "                          tau=model_cfg['tau']).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model_path = os.path.join(trained_models_dir, model_file)\n",
    "    print(f\"Evaluating {model_file}...\")\n",
    "\n",
    "    # loads the respective model\n",
    "    model.load(model_path)\n",
    "\n",
    "    # calculates accuracy\n",
    "    accuracy = model.get_accuracy(test_loader)\n",
    "    \n",
    "    print(f\"Accuracy of {model_file}: {accuracy * 100:.2f}%\\n\")\n",
    "    \n",
    "    trained_models[i] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e3a6a-900e-47f8-9796-75de4c4cddde",
   "metadata": {},
   "source": [
    "#### Logic Gate and Connection Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e21b9e6a-50e4-4f63-9331-9abfc8669053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extracts the learned gates and connections from the difflogic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd2b5d-ed32-4ff0-9c40-caa7169ae1ed",
   "metadata": {},
   "source": [
    "#### Model Optimization (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8665f3c-8c20-400e-a147-d92abac655eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# maybe remove the unused nodes to increase inference speed / decrease energy consumption?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c06262-afe8-4b02-883c-c044a060fc39",
   "metadata": {},
   "source": [
    "#### Verilog Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e20496-c3ac-4d87-8e55-359ac0069b03",
   "metadata": {},
   "source": [
    "Logic gate to Verilog expression mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2846e8b8-9b6f-49dc-adbc-7bfe8fe0a27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logic_gate_verilog = {\n",
    "    \"0\": \"1'b0\",\n",
    "    \"A∧B\": \"({a}) & ({b})\",\n",
    "    \"¬(A⇒B)\": \"({a}) & ~({b})\",\n",
    "    \"A\": \"{a}\",\n",
    "    \"¬(B⇒A)\": \"({b}) & ~({a})\",\n",
    "    \"B\": \"{b}\",\n",
    "    \"A⊕B\": \"({a}) ^ ({b})\",\n",
    "    \"A∨B\": \"({a}) | ({b})\",\n",
    "    \"¬(A∨B)\": \"~(({a}) | ({b}))\",\n",
    "    \"¬(A⊕B)\": \"~(({a}) ^ ({b}))\",\n",
    "    \"¬B\": \"~({b})\",\n",
    "    \"B⇒A\": \"~({b}) | ({a})\",\n",
    "    \"¬A\": \"~({a})\",\n",
    "    \"A⇒B\": \"~({a}) | ({b})\",\n",
    "    \"¬(A∧B)\": \"~(({a}) & ({b}))\",\n",
    "    \"1\": \"1'b1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0a28141-16b1-4e15-8adc-a4aa7cb405cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "N_input = 1024  # number of input dimensions\n",
    "N_output = 10  # number of output dimensions (classes)\n",
    "\n",
    "# converts the learned logic gates to verilog or vhdl \n",
    "def generate_verilog(model, filename=\"logic_network.v\"):\n",
    "    \n",
    "    N_layers = len(model.logic_layers)\n",
    "\n",
    "    # gets number of neurons per layer\n",
    "    neurons_per_layer = [layer.weights.size()[0] for layer in model.logic_layers]\n",
    "\n",
    "    with open(filename, 'w') as file:\n",
    "        # module declaration\n",
    "        file.write(\"module logic_network(\\n\")\n",
    "        file.write(f\"    input wire [{N_input-1}:0] inputs,\\n\")\n",
    "        file.write(f\"    output wire [{N_output-1}:0] outputs\\n\")\n",
    "        file.write(\");\\n\\n\")\n",
    "\n",
    "        # declares wires for internal layers\n",
    "        for layer_index in range(N_layers - 1):\n",
    "            N_neurons = neurons_per_layer[layer_index]\n",
    "            file.write(f\"    wire [{N_neurons -1}:0] layer{layer_index}_outputs;\\n\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "        logic_operations = list(logic_gate_verilog.keys())\n",
    "\n",
    "        for layer_index in range(N_layers):\n",
    "            logic_layer = model.logic_layers[layer_index]\n",
    "\n",
    "            # gets input and output indices\n",
    "            input_indices = logic_layer.indices[0].cpu().numpy()  # first input indices\n",
    "            output_indices = logic_layer.indices[1].cpu().numpy()  # second input indices\n",
    "\n",
    "            neuron_gates = [torch.argmax(logic_layer.weights[neuron]).item()\n",
    "                            for neuron in range(logic_layer.weights.size()[0])]\n",
    "            connections = {i: (input_indices[i], output_indices[i]) for i in range(len(neuron_gates))}\n",
    "\n",
    "            N_neurons = neurons_per_layer[layer_index]\n",
    "\n",
    "            # determines input wires\n",
    "            if layer_index == 0:\n",
    "                input_wire_base = \"inputs\"\n",
    "            else:\n",
    "                input_wire_base = f\"layer{layer_index -1}_outputs\"\n",
    "\n",
    "            # determines output wires\n",
    "            if layer_index == N_layers - 1:\n",
    "                output_wire_base = \"outputs\"\n",
    "            else:\n",
    "                output_wire_base = f\"layer{layer_index}_outputs\"\n",
    "\n",
    "            # assign statements for this layer\n",
    "            for neuron_id in range(N_neurons):\n",
    "                a_idx, b_idx = connections[neuron_id]\n",
    "\n",
    "                # maps indices to input wires\n",
    "                a_wire = f\"{input_wire_base}[{a_idx}]\"\n",
    "                b_wire = f\"{input_wire_base}[{b_idx}]\"\n",
    "\n",
    "                # gets gate\n",
    "                gate_op = logic_operations[neuron_gates[neuron_id]]\n",
    "                gate = logic_gate_verilog[gate_op].format(a=a_wire, b=b_wire)\n",
    "\n",
    "                # assigns to output wire\n",
    "                output_wire = f\"{output_wire_base}[{neuron_id}]\"\n",
    "\n",
    "                file.write(f\"    assign {output_wire} = {gate};\\n\")\n",
    "\n",
    "        file.write(\"endmodule\\n\")\n",
    "        print('success')\n",
    "\n",
    "# generates Verilog file for all trained models\n",
    "for model_idx in range(len(trained_models)):\n",
    "    i = model_idx + 1\n",
    "    generate_verilog(trained_models[model_idx], filename=f\"verilog/model_{i:03d}_logic_network.v\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DIFFLOGIC",
   "language": "python",
   "name": "difflogic_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
