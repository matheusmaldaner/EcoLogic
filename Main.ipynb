{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df65bb0b-594d-4717-bd3c-63b04b9d864b",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb5dd1c0-73cf-4679-ae21-6fa00a85a395",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import torchvision.transforms as transforms\n",
    "import mnist_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99c41f-b5c7-4d64-a704-5a003a5b56c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8096d-fc17-46d7-861e-685d2fe12dbb",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ea8409-a084-4bee-8121-96acd99bb28e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# True: 20x20 MNIST, False: 28x28 MNIST\n",
    "small_mnist = True\n",
    "# True: Binarized Images, False: Grayscale Images \n",
    "binarize_images = True  \n",
    "# True: Even distribution of samples, False: Original Mnist distribution \n",
    "evenly_partitioned = True\n",
    "# Batch size\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4450630-e7a8-4564-b106-6e2dc3a12e61",
   "metadata": {},
   "source": [
    "Dataset Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1779afcd-2def-41d1-abdc-c1bc8dbb1719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to binarize an image, threshold is tunable \n",
    "def binarize(image, threshold=0.5):\n",
    "    return (image > threshold).float()  \n",
    "\n",
    "# define the transformation logic based on the toggle\n",
    "if binarize_images:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: binarize(x))  # apply binarization if enabled\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()  # just convert to tensor if not binarizing\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5db70-d2ba-44a7-803c-829177a182c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Dataset Evenly Partitioned\n",
    "if evenly_partitioned:\n",
    "    # code below is used so that all classes have the same number of samples\n",
    "    train_targets = train_loader.dataset.targets\n",
    "    test_targets = test_loader.dataset.targets\n",
    "\n",
    "    train_digits_total = []\n",
    "    test_digits_total = []\n",
    "\n",
    "    for i in range(10):\n",
    "        curr_tot_train = torch.sum(train_targets == i).item()\n",
    "        curr_tot_test = torch.sum(test_targets == i).item()    \n",
    "        train_digits_total.append(curr_tot_train)\n",
    "        test_digits_total.append(curr_tot_test)\n",
    "\n",
    "    train_digits_total, test_digits_total\n",
    "\n",
    "    # find the minimum number of samples across all classes\n",
    "    min_samples_train = min(train_digits_total)\n",
    "    min_samples_test = min(test_digits_total)\n",
    "\n",
    "    # function to trim dataset to match the minimum samples for each class and shuffle indices\n",
    "    def trim_dataset(dataset, targets, min_samples):\n",
    "        indices = []\n",
    "        for i in range(10):\n",
    "            class_indices = (targets == i).nonzero(as_tuple=True)[0]  # get indices of class i\n",
    "            class_indices = class_indices[:min_samples]  # trim to min_samples\n",
    "            indices.extend(class_indices)\n",
    "\n",
    "        # shuffle indices after collecting them\n",
    "        indices = torch.tensor(indices)\n",
    "        indices = indices[torch.randperm(indices.size(0))]  \n",
    "\n",
    "        return Subset(dataset, indices)\n",
    "\n",
    "    # trim both train and test datasets to ensure all classes have the same number of samples\n",
    "    trimmed_train_dataset = trim_dataset(train_loader.dataset, train_targets, min_samples_train)\n",
    "    trimmed_test_dataset = trim_dataset(test_loader.dataset, test_targets, min_samples_test)\n",
    "\n",
    "    # create DataLoaders for the trimmed datasets\n",
    "    trimmed_train_loader = DataLoader(trimmed_train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    trimmed_test_loader = DataLoader(trimmed_test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, drop_last=True)\n",
    "\n",
    "    # verify the lengths of the trimmed datasets\n",
    "    len(trimmed_train_loader.dataset), len(trimmed_test_loader.dataset)\n",
    "\n",
    "    train_dataset = trimmed_train_dataset\n",
    "    test_dataset = trimmed_test_dataset\n",
    "    train_loader = trimmed_train_loader\n",
    "    test_loader = trimmed_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b93eeef-8838-4e9a-9d87-0444073558f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# populate with MNIST or other datasets we want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973f0e3-5f32-4793-afc6-9394425419de",
   "metadata": {},
   "source": [
    "#### Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc64546-f1d7-4e18-b88c-7140d4d42692",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file 'mnist_config_16x16.yaml' generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# populate by reading the hyperparameters for different models we want to test\n",
    "# also converts csv into yaml config file\n",
    "\n",
    "# converts the hyperparameters into a config.yaml file to train multiple models\n",
    "first_in_dim = 256 # 16x16\n",
    "filename = \"mnist_config_16x16.yaml\"  \n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"hyperparameters.csv\")\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries\n",
    "models = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Create the YAML structure\n",
    "yaml_structure = {\"models\": {}}\n",
    "\n",
    "# Function to round the number to the nearest multiple of the output size\n",
    "def round_to_nearest_multiple(value, multiple):\n",
    "    return multiple * round(value / multiple)\n",
    "\n",
    "# populate the YAML structure with models\n",
    "for i, model in enumerate(models, start=1):\n",
    "    # zero-pad model names to 3 digits \n",
    "    model_name = f\"model_{str(i).zfill(3)}\"\n",
    "    layers_config = {}\n",
    "    \n",
    "    for layer in range(1, model[\"H\"] + 1):\n",
    "        # zero-pad layer names to 3 digits\n",
    "        layer_name = f\"LogicLayer{str(layer).zfill(3)}\"\n",
    "        \n",
    "        # Adjust in_dim to the nearest multiple of 10\n",
    "        in_dim = first_in_dim if layer == 1 else round_to_nearest_multiple(model[\"W\"], 10)\n",
    "        \n",
    "        # Adjust out_dim to the nearest multiple of 10\n",
    "        out_dim = round_to_nearest_multiple(model[\"W\"], 10)\n",
    "        \n",
    "        layers_config[layer_name] = {\n",
    "            \"in_dim\": in_dim,\n",
    "            \"out_dim\": out_dim,\n",
    "            \"device\": \"cuda\",\n",
    "            \"implementation\": \"cuda\",\n",
    "            \"connections\": \"random\",\n",
    "            \"grad_factor\": 2, # we can try different grad_factor values as well\n",
    "        }\n",
    "    \n",
    "    yaml_structure[\"models\"][model_name] = {\n",
    "        \"input_dim\": first_in_dim, \n",
    "        \"output_size\": 10, # for MNIST classification\n",
    "        \"tau\": model[\"tau\"],\n",
    "        \"learning_rate\": model[\"lr\"],\n",
    "        \"layers_config\": layers_config,\n",
    "    }\n",
    "\n",
    "# Save to a YAML file\n",
    "with open(f'{filename}', \"w\") as file:\n",
    "    yaml.dump(yaml_structure, file, default_flow_style=False)\n",
    "\n",
    "print(f\"YAML file '{filename}' generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e939ace-e4c3-4781-bdea-f9722ddb925e",
   "metadata": {},
   "source": [
    "#### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c480c2-c0be-490f-b30d-78e09cb6bfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c39cff9-351c-4f36-97df-a240f39d6afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defines the class for the DiffLogic architecture, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b244edec-9bd5-474d-9aaa-4f9aafe31b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffLogic(nn.Module):\n",
    "    def __init__(self, layers_config, output_size, tau=30):\n",
    "        \"\"\"\n",
    "        Initializes the DiffLogic model with the specified layer configurations, output size, and temperature parameter.\n",
    "\n",
    "        Args:\n",
    "            layers_config (dict): Configuration for each logic layer, including dimensions, device, implementation, connections, and grad factor.\n",
    "            output_size (int): The number of output groups.\n",
    "            tau (int): Temperature parameter for the GroupSum operation.\n",
    "        \"\"\"\n",
    "        super(DiffLogic, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        layers = []\n",
    "        for layer_name, config in layers_config.items():\n",
    "            layer = LogicLayer(\n",
    "                in_dim=config['in_dim'],\n",
    "                out_dim=config['out_dim'],\n",
    "                device=config['device'],\n",
    "                implementation=config['implementation'],\n",
    "                connections=config['connections'],\n",
    "                grad_factor=config['grad_factor']       \n",
    "            )\n",
    "            layers.append(layer)\n",
    "            print(layer)\n",
    "        \n",
    "        self.logic_layers = nn.Sequential(*layers)\n",
    "        \n",
    "        self.group = GroupSum(k=output_size, tau=tau)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the DiffLogic model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after processing through the logic layers and grouping operation.\n",
    "        \"\"\"\n",
    "        # Move tensor to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.to('cuda')          \n",
    "        x = self.flatten(x)\n",
    "        logits = self.logic_layers(x)\n",
    "        group = self.group(logits)\n",
    "        return group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd97e0b-c6c4-4262-97ab-32136126ba39",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea90015-6e45-49af-bb11-539c8811adcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training loop for all models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28a834-adac-4241-83a4-d9a23ac17db5",
   "metadata": {},
   "source": [
    "#### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33048f62-fc21-4f87-b725-6eb470a66700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing loop to test inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e3a6a-900e-47f8-9796-75de4c4cddde",
   "metadata": {},
   "source": [
    "#### Logic Gate and Connection Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e21b9e6a-50e4-4f63-9331-9abfc8669053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extracts the learned gates and connections from the difflogic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd2b5d-ed32-4ff0-9c40-caa7169ae1ed",
   "metadata": {},
   "source": [
    "#### Model Optimization (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8665f3c-8c20-400e-a147-d92abac655eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# maybe remove the unused nodes to increase inference speed / decrease energy consumption?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c06262-afe8-4b02-883c-c044a060fc39",
   "metadata": {},
   "source": [
    "#### Verilog Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a28141-16b1-4e15-8adc-a4aa7cb405cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# converts the learned gates to verilog or vhdl "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DIFFLOGIC",
   "language": "python",
   "name": "difflogic_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
